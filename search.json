[
  {
    "objectID": "ml-systems.html",
    "href": "ml-systems.html",
    "title": "List of ML Systems from the market",
    "section": "",
    "text": "Machine Learning Systems _\n    \n    \n        ML systems can be divided into several categories, including supervised learning, unsupervised learning, and reinforcement learning. \n    \n\n\n\n\n\n\nIn supervised learning, the system is trained on labeled data, where the correct output is known for each input. In unsupervised learning, the system is trained on unlabeled data, where the goal is to identify patterns and relationships in the data. In reinforcement learning, the system learns through trial and error, where it receives feedback in the form of rewards or penalties based on its actions.\nML systems require large amounts of data to train effectively, and the quality and quantity of the data can have a significant impact on the performance of the system. ML systems also require careful design and tuning to ensure that they are accurate, reliable, and scalable.\nDespite these challenges, ML systems have the potential to revolutionize many industries and improve our lives in countless ways. As the field of ML continues to evolve, we can expect to see even more powerful and sophisticated systems that can tackle increasingly complex tasks and challenges.\nIf you are looking for ideas to learn machine learning, here are some market examples.\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\n\n\nfrom IPython.display import display\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\n\ndf = pd.read_csv('dataset/ml-system.csv')\ntag_counts = df['Tag'].value_counts().head(10)\nfig = px.bar(tag_counts, orientation='h')\n\nfig.update_layout(\n    paper_bgcolor='rgba(0,0,0,0)', \n    plot_bgcolor='rgba(0,0,0,0)',\n    images=[dict(\n        xref=\"paper\", yref=\"paper\",\n        x=0.5, y=0.5,\n        sizex=1, sizey=1,\n        opacity=0.5,\n        layer=\"below\")],\n    font=dict(\n        color=\"#6f6feb\",\n    ),\n    margin=dict(\n        l=5,\n        r=5,\n        b=5,\n        t=5,\n        pad=4\n    )\n)\n\nfig.show()\n\ndf_short = df.drop(['Industry', 'Year', 'Short Description (&lt; 5 words)', 'Link'], axis=1)\n\ndisplay(df_short.head(10))\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\nCompany\nTitle\nTag\n\n\n\n\n0\nStripe\nHow we built it: Stripe Radar\nfraud detection\n\n\n1\nWalmart\nPersonalized ‘Complete the Look’ model\nrecommender system,product feature,CV\n\n\n2\nUber\nDemand and ETR Forecasting at Airports\ndemand forecasting\n\n\n3\nPinterest\nAn ML based approach to proactive advertiser c...\nchurn prediction\n\n\n4\nStitch Fix\nA New Era of Creativity: Expert-in-the-loop Ge...\nproduct feature,NLP,generative AI\n\n\n5\nSwiggy\nBuilding a mind reader at Swiggy using Data Sc...\nproduct feature,recommender system\n\n\n6\nMicrosoft\nLarge-language models for automatic cloud inci...\nops,generative AI,product feature\n\n\n7\nFoodpanda\nMenu Ranking\ncontent personalization\n\n\n8\nZillow\nBuilding the Neural Zestimate\npricing\n\n\n9\nAirbnb\nPrioritizing Home Attributes Based on Guest In...\nNLP,item classification,search\n\n\n\n\n\n\n\n\nSome Definitions\nETA prediction model is a machine learning model that predicts the estimated time of arrival for a given task or process. It is a type of regression model that uses historical data to learn patterns and make predictions about future events.\nProduct feature is designed to identify and extract product features from textual data such as product descriptions, reviews, and specifications. These systems use natural language processing (NLP) techniques to analyze the text and identify the specific features that are being discussed.\nContent personalization is designed to personalize product content for individual users based on their preferences, behavior, and other relevant data. These systems use machine learning algorithms to analyze user data and generate personalized product content that is tailored to the user’s needs and preferences.\nItem classification is designed to classify items into different categories or classes based on their features or attributes. These systems use machine learning algorithms to analyze the features of the items and identify patterns that are associated with specific classes.\nDemand forecasting is designed to predict the future demand for a product or service based on historical data and other relevant factors. These systems use machine learning algorithms to analyze patterns and trends in the data and generate forecasts of future demand.\n\n\n\nReferences\n\nhttps://airtable.com/shrZeywfF21lfSjci/tblTCefZr4laRvmqI\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/decision-making/index.html#data-can-reveal-correlations-relationships-and-potential-consequences.-however-understanding-of-the-data-require-human-reasoning-critical-thinking-and-context-specific-knowledge.",
    "href": "posts/decision-making/index.html#data-can-reveal-correlations-relationships-and-potential-consequences.-however-understanding-of-the-data-require-human-reasoning-critical-thinking-and-context-specific-knowledge.",
    "title": "Data-Driven and Intuition-Based Approaches in Decision-Making",
    "section": "Data can reveal correlations, relationships, and potential consequences. However, understanding of the data require human reasoning, critical thinking, and context-specific knowledge.",
    "text": "Data can reveal correlations, relationships, and potential consequences. However, understanding of the data require human reasoning, critical thinking, and context-specific knowledge.\nA decision refers to being resolute and having a clear judgment or opinion on a matter. It involves making a firm decision or having a determined purpose. Although important, data can’t replace the human aspects of decision-making such as emotional intelligence, empathy, and moral judgment, as they cannot be fully captured by data.\n\n\n\n\nIt’s crucial to note that neither method has a built-in advantage over the other. The best choice depends entirely on the specific context and situation at hand.\n\n\n\n\nBright Glass Abstract by Cláudia Silva\n\n\n\n\n\n\n\n\nflowchart TB\n  C{Decision-making} --&gt; D[Data-Driven Decisions]\n  C --&gt; E[Intuition-Based Decisions]\n  D --&gt; X[Sensitive with historical data]\n  E --&gt; Y[Sensitive with biases, and not repeatable]\n  X --&gt; Z[Data-informed decisions, if possible] \n  Y --&gt; Z\n\n\n\n\n\n\n\n\nData-Driven Decisions: This is often the preferred method in situations where a large amount of quantitative information is available and the decision-making environment is stable and predictable. It tends to be more objective and can help reduce biases in decision-making. Data-driven decision-making is often used in fields like finance, marketing, and logistics where there’s plenty of historical data to analyze and predict future trends. However, it’s crucial to ensure that the data is reliable, accurate, and relevant to the decision at hand.\nThe data-driven decision making can be time-consuming, require specialized skills, and may not be applicable in novel situations with no past data to rely upon.\nIntuition-Based Decisions: This is typically used in situations where there’s a lack of data, the environment is highly uncertain or rapidly changing, or the decision involves complex qualitative factors that are difficult to quantify. It often leverages personal experience, instincts, and tacit knowledge. Entrepreneurs, for instance, often rely on their intuition to make strategic decisions about new products or markets.\nThis approach can be prone to cognitive biases and may not always be repeatable or justifiable to others.\n\nIn practice, the most effective decision-making often involves a combination of both data-driven and intuition-based methods. This is often called “data-informed” decision-making. It means you use data as a key input, but you also consider other factors, like your own intuition, qualitative insights, and contextual factors that the data may not fully capture. This approach provides a more holistic view of the situation and allows for more nuanced and adaptable decisions.\nRemember that data is a tool to inform decisions, not to make them. There’s a human aspect to decision-making that can’t be replaced by data. Emotional intelligence, empathy, and moral judgment are all aspects that data can’t fully encompass.\n\n\n\n\n\n\nLet’s have an example /\n\n\n\n\n\nImagine we have a dataset about student performance. A data-driven decision might be to identify students who need additional support based on their grades.\n\n\nWe can use a basic Python illustration to showcase how data-driven and intuition-based decision-making can complement each other. Here’s how we might do it:\n\n\nCode\nimport pandas as pd\n\n# Assuming you have a pandas DataFrame 'df' with students' names and their grades.\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Ella'],\n    'Grade': [85, 70, 78, 64, 92]\n})\n\n# We could decide that any student with a grade below 75 needs additional support.\nstudents_needing_support = df[df['Grade'] &lt; 75]\n\nprint(students_needing_support)\n\n\n    Name  Grade\n1    Bob     70\n3  David     64\n\n\nIn this case, we made a data-driven decision that Bob and David need additional support because their grades were below 75. But what if there’s more to the story? Let’s say, we know from talking to the teachers (intuition-based/qualitative input) that Alice, despite her high grade, has been struggling with personal issues and might benefit from additional support.\nWe could incorporate this intuition-based insight into our decision-making process like so:\n\n\nCode\n# Add Alice to the list of students needing support.\n\nalice_df = df[df['Name'] == 'Alice']\n\n\nstudents_needing_support = pd.concat([students_needing_support, alice_df])\n\nprint(students_needing_support)\n\n\n    Name  Grade\n1    Bob     70\n3  David     64\n0  Alice     85\n\n\n\n\n\n\n\nThe Conclusion /\n\n\n\n\n\nOur approach is to use data as a guide for making decisions while also taking into account qualitative insights and intuition. It’s important to remember that data should inform decisions, but not be the sole basis for making them.\n\n\n\n\n\nThank you for reading"
  },
  {
    "objectID": "posts/read-multiple-csv/index.html",
    "href": "posts/read-multiple-csv/index.html",
    "title": "Read Multiple CSVs Files",
    "section": "",
    "text": "multiple_csv.py\n\nimport pandas as pd\nimport time\nstart = time.time()\n# File list into the array list\ndata_list = [\"data-0{0}.tsv\".format(i) for i in range(1, 8)]\ndata_name = []\nfor i in range(7):\n  x = data_list[i].strip(\".tsv\")\n  data_name.append(x)\n\nfor i in range(7):\n  data_name[i] = pd.read_csv(\"../url_path/{0}.tsv\".format(data_name[i]), sep='\\t', nrows=10000)\nfor i in range(7):\n  print(data_name[i].head())\nend = time.time()\n\nprint(\"Total time of the process:\", end-start)\nwhile end-start &lt; 1:\n  print(\"We have processed all files less than one minute.\")\n  break"
  },
  {
    "objectID": "posts/two-sample-z-test/index.html",
    "href": "posts/two-sample-z-test/index.html",
    "title": "Two Sample Z-Test",
    "section": "",
    "text": "two_samples_z_test.py\n\ndef twoSampZ(X1, X2, mudiff, sd1, sd2, n1, n2):\n    from numpy import sqrt, abs, round\n    from scipy.stats import norm\n    pooledSE = sqrt(sd1**2/n1 + sd2**2/n2)\n    z = ((X1 - X2) - mudiff)/pooledSE\n    pval = 2*(norm.sf(abs(z)))\n    return round(z, 9), round(pval, 9)\n\n\nz, p = twoSampZ(79.24, 73.74, 0, 19.76, 16.86, 174, 159)\na, b = twoSampZ(109.31, 113.42, 0, 27.671, 25.464, 206, 190)\n\nprint(z, p)\nprint(a, b)"
  },
  {
    "objectID": "posts/about-euler/index.html",
    "href": "posts/about-euler/index.html",
    "title": "Euler’s Identity",
    "section": "",
    "text": "Euler’s identity is often cited as an example of deep mathematical beauty. Three basic arithmetic operations occur exactly once and combine five fundamental mathematical constants [1].\nThe Identity\nStarting from Euler’s formula \\(e^{ix}=\\cos x + i\\sin x\\) for any real number \\(x\\), we get to Euler’s identity with the special case of \\(x = \\pi\\)\n\\[e^{i\\pi}+1=0\\,.\\] (1)\nThe arithmetic operations addition, multiplication and exponentiation combine the fundamental constants\n\nthe additive identity \\(0\\).\nthe multiplicative identity \\(1\\).\nthe circle constant \\(\\pi\\).\nEuler’s number \\(e\\).\nthe imaginary constant \\(i\\).\n\nConclusion\nIt has been shown, how Euler’s identity makes a valid formula from five mathematical constants.\nReferences\n[1] Euler’s identity"
  },
  {
    "objectID": "posts/regression/simple.html",
    "href": "posts/regression/simple.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Simple linear regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables. This method is widely used for predictive analysis. This article will delve into the concept of simple linear regression, its assumptions, how it works, its applications, and limitations.\n\n\nSimple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable. The objective of simple linear regression is to model the expected relationship between the two variables.\nThe relationship is represented by the following equation:\n\\[\nY = a + bX + e\n\\]\nHere, (Y) is the dependent variable we’re trying to predict or estimate; (X) is the independent variable we’re using to make predictions; (a) represents the intercept of the regression line; (b) represents the slope of the regression line and shows the rate at which (Y) changes for each change in (X); (e) is the error term (also known as the residual errors), the part of (Y) the regression model couldn’t explain.\n\n\n\nSimple linear regression makes five key assumptions:\n\nLinearity: The relationship between (X) and the mean of (Y) is linear.\nHomoscedasticity: The variance of residual is the same for any value of (X).\nIndependence: Observations are independent of each other.\nNormality: For any fixed value of (X), (Y) is normally distributed.\nError term has a mean of zero: The mean of the distribution of errors is assumed to be zero.\n\n\n\n\nThe goal of simple linear regression is to create a linear model that minimizes the sum of squares of the residuals/error terms. The steps to perform simple linear regression are:\n\nEstimate the Coefficients: The coefficients (a) and (b) are estimated using the least-squares criterion, which means we find the line (mathematically) which minimizes the sum of squared residuals (or “sum of squared errors”).\nFit the Model: Once we find the coefficients, we can use them to predict the output(y) of a given independent variable (X). This line is the “line of best fit”.\nInterpret the Coefficients: The coefficients can be interpreted as the change in the dependent variable for each one-unit change in the independent variable, assuming all other variables are held constant.\n\n\n\n\nSimple linear regression is used in a wide array of fields. Some examples include:\n\nFinance: Predicting the impact of changes in interest rates on stock price.\nReal Estate: Predicting house prices based on the house size.\nMarketing: Predicting sales based on the amount spent on advertising.\nSupply Chain: Predicting the time to deliver a product based on the distance.\n\n\n\n\nWhile simple linear regression is a powerful tool, it has its limitations:\n\nLinearity & Independence Assumption: The assumption of Linearity and Independence may not hold in many scenarios. For example, predicting disease progression; it is not necessary that the progression is linear and independent always.\nOutliers: Simple linear regression is sensitive to outliers. A single outlier can significantly change the model’s predictions.\nLimited to two variables: As it is a simple linear regression, it can only consider a single independent variable. In many cases, a phenomenon can be influenced by multiple variables\nProne to Overfitting: If the model is too complex, it can become overfitted. An overfitted model will perform well on the training data but poorly on unseen data.\n\n\n\n\nSimple linear regression is a fundamental statistical technique that has found application in a wide range of fields due to its simplicity and interpretability. It serves as a good starting point for more complex analysis and is a cornerstone in understanding the basics of machine learning. However, it is essential to understand its assumptions and limitations to interpret the results accurately."
  },
  {
    "objectID": "posts/regression/simple.html#what-is-simple-linear-regression",
    "href": "posts/regression/simple.html#what-is-simple-linear-regression",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable. The objective of simple linear regression is to model the expected relationship between the two variables.\nThe relationship is represented by the following equation:\n\\[\nY = a + bX + e\n\\]\nHere, (Y) is the dependent variable we’re trying to predict or estimate; (X) is the independent variable we’re using to make predictions; (a) represents the intercept of the regression line; (b) represents the slope of the regression line and shows the rate at which (Y) changes for each change in (X); (e) is the error term (also known as the residual errors), the part of (Y) the regression model couldn’t explain."
  },
  {
    "objectID": "posts/regression/simple.html#assumptions-of-simple-linear-regression",
    "href": "posts/regression/simple.html#assumptions-of-simple-linear-regression",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Simple linear regression makes five key assumptions:\n\nLinearity: The relationship between (X) and the mean of (Y) is linear.\nHomoscedasticity: The variance of residual is the same for any value of (X).\nIndependence: Observations are independent of each other.\nNormality: For any fixed value of (X), (Y) is normally distributed.\nError term has a mean of zero: The mean of the distribution of errors is assumed to be zero."
  },
  {
    "objectID": "posts/regression/simple.html#how-does-simple-linear-regression-work",
    "href": "posts/regression/simple.html#how-does-simple-linear-regression-work",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "The goal of simple linear regression is to create a linear model that minimizes the sum of squares of the residuals/error terms. The steps to perform simple linear regression are:\n\nEstimate the Coefficients: The coefficients (a) and (b) are estimated using the least-squares criterion, which means we find the line (mathematically) which minimizes the sum of squared residuals (or “sum of squared errors”).\nFit the Model: Once we find the coefficients, we can use them to predict the output(y) of a given independent variable (X). This line is the “line of best fit”.\nInterpret the Coefficients: The coefficients can be interpreted as the change in the dependent variable for each one-unit change in the independent variable, assuming all other variables are held constant."
  },
  {
    "objectID": "posts/regression/simple.html#applications-of-simple-linear-regression",
    "href": "posts/regression/simple.html#applications-of-simple-linear-regression",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Simple linear regression is used in a wide array of fields. Some examples include:\n\nFinance: Predicting the impact of changes in interest rates on stock price.\nReal Estate: Predicting house prices based on the house size.\nMarketing: Predicting sales based on the amount spent on advertising.\nSupply Chain: Predicting the time to deliver a product based on the distance."
  },
  {
    "objectID": "posts/regression/simple.html#limitations-of-simple-linear-regression",
    "href": "posts/regression/simple.html#limitations-of-simple-linear-regression",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "While simple linear regression is a powerful tool, it has its limitations:\n\nLinearity & Independence Assumption: The assumption of Linearity and Independence may not hold in many scenarios. For example, predicting disease progression; it is not necessary that the progression is linear and independent always.\nOutliers: Simple linear regression is sensitive to outliers. A single outlier can significantly change the model’s predictions.\nLimited to two variables: As it is a simple linear regression, it can only consider a single independent variable. In many cases, a phenomenon can be influenced by multiple variables\nProne to Overfitting: If the model is too complex, it can become overfitted. An overfitted model will perform well on the training data but poorly on unseen data."
  },
  {
    "objectID": "posts/regression/simple.html#conclusion",
    "href": "posts/regression/simple.html#conclusion",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "Simple linear regression is a fundamental statistical technique that has found application in a wide range of fields due to its simplicity and interpretability. It serves as a good starting point for more complex analysis and is a cornerstone in understanding the basics of machine learning. However, it is essential to understand its assumptions and limitations to interpret the results accurately."
  },
  {
    "objectID": "posts/regression/multiple.html",
    "href": "posts/regression/multiple.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Multiple linear regression (MLR) is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. The goal of MLR is to model the linear relationship between the explanatory (independent) variables and response (dependent) variable.\nIn essence, multiple linear regression is an extension of simple linear regression, which predicts the outcome of a dependent variable based on a single independent variable. In contrast, MLR predicts the outcome based on two or more independent variables.\n\n\n\nThe general mathematical equation for a multiple regression is:\n\\[\nY = b_0 + b_1*X_1 + b_2*X_2 + ... + b_n*X_n + ε\n\\]\nWhere:\n\n(Y) is the dependent variable.\n(X_1, X_2, …, X_n) are the independent variables.\n(b_0) is the y-intercept.\n(b_1, b_2, …, b_n) are the regression coefficients, representing the change in (Y) for a one-unit change in the corresponding (X).\n(ε) is the error term, which is the part of (Y) the regression model couldn’t explain.\n\nEach coefficient (b) estimates the effect of one independent variable on the dependent variable, holding all other independent variables constant.\n\n\n\nMultiple linear regression analysis makes several key assumptions:\n\nLinearity: The relationship between the independent and dependent variables is linear.\nIndependence: The residuals are independent. In particular, there’s no correlation between consecutive residuals in time series data.\nHomoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\nNormality: The residuals of the model are normally distributed.\nLack of multicollinearity: The independent variables are not too highly correlated with each other.\n\nViolation of these assumptions can lead to various problems, including unreliable and unstable estimates of regression coefficients. Diagnostic tests and plots can help check these assumptions.\n\n\n\nMultiple linear regression is used in various fields, including machine learning, business, medical research, social sciences, and engineering. For example:\n\nIn business, it can be used to predict future sales based on the advertising expenditure and economic variables like GDP and unemployment rates.\nIn healthcare, it can be used to understand the impact of various lifestyle factors on health outcomes. For example, predicting life expectancy based on diet, physical activity, and environmental factors.\nIn machine learning, it’s a common method for supervised learning with a continuous outcome.\n\n\n\n\nMultiple linear regression is a powerful statistical tool that allows researchers to examine the relationship between two or more variables. It’s a fundamental technique in many areas of study, offering the ability to make predictions and understand relationships in data.\nHowever, like all statistical techniques, it comes with assumptions that must be checked to ensure reliable results. Violations of these assumptions can lead to biased or inefficient estimates. Therefore, it’s essential to understand these assumptions and how to check them when using multiple linear regression."
  },
  {
    "objectID": "posts/regression/multiple.html#introduction",
    "href": "posts/regression/multiple.html#introduction",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Multiple linear regression (MLR) is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. The goal of MLR is to model the linear relationship between the explanatory (independent) variables and response (dependent) variable.\nIn essence, multiple linear regression is an extension of simple linear regression, which predicts the outcome of a dependent variable based on a single independent variable. In contrast, MLR predicts the outcome based on two or more independent variables."
  },
  {
    "objectID": "posts/regression/multiple.html#mathematical-representation",
    "href": "posts/regression/multiple.html#mathematical-representation",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "The general mathematical equation for a multiple regression is:\n\\[\nY = b_0 + b_1*X_1 + b_2*X_2 + ... + b_n*X_n + ε\n\\]\nWhere:\n\n(Y) is the dependent variable.\n(X_1, X_2, …, X_n) are the independent variables.\n(b_0) is the y-intercept.\n(b_1, b_2, …, b_n) are the regression coefficients, representing the change in (Y) for a one-unit change in the corresponding (X).\n(ε) is the error term, which is the part of (Y) the regression model couldn’t explain.\n\nEach coefficient (b) estimates the effect of one independent variable on the dependent variable, holding all other independent variables constant."
  },
  {
    "objectID": "posts/regression/multiple.html#assumptions-of-multiple-linear-regression",
    "href": "posts/regression/multiple.html#assumptions-of-multiple-linear-regression",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Multiple linear regression analysis makes several key assumptions:\n\nLinearity: The relationship between the independent and dependent variables is linear.\nIndependence: The residuals are independent. In particular, there’s no correlation between consecutive residuals in time series data.\nHomoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\nNormality: The residuals of the model are normally distributed.\nLack of multicollinearity: The independent variables are not too highly correlated with each other.\n\nViolation of these assumptions can lead to various problems, including unreliable and unstable estimates of regression coefficients. Diagnostic tests and plots can help check these assumptions."
  },
  {
    "objectID": "posts/regression/multiple.html#applications-of-multiple-linear-regression",
    "href": "posts/regression/multiple.html#applications-of-multiple-linear-regression",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Multiple linear regression is used in various fields, including machine learning, business, medical research, social sciences, and engineering. For example:\n\nIn business, it can be used to predict future sales based on the advertising expenditure and economic variables like GDP and unemployment rates.\nIn healthcare, it can be used to understand the impact of various lifestyle factors on health outcomes. For example, predicting life expectancy based on diet, physical activity, and environmental factors.\nIn machine learning, it’s a common method for supervised learning with a continuous outcome."
  },
  {
    "objectID": "posts/regression/multiple.html#conclusion",
    "href": "posts/regression/multiple.html#conclusion",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Multiple linear regression is a powerful statistical tool that allows researchers to examine the relationship between two or more variables. It’s a fundamental technique in many areas of study, offering the ability to make predictions and understand relationships in data.\nHowever, like all statistical techniques, it comes with assumptions that must be checked to ensure reliable results. Violations of these assumptions can lead to biased or inefficient estimates. Therefore, it’s essential to understand these assumptions and how to check them when using multiple linear regression."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning is a gift that you can give yourself every day",
    "section": "",
    "text": "Curiosity & Problem Solving Mindset _\n    \n    \n        Data science is a discipline that lies at the intersection of mathematics, computer science, and business acumen. And a lot of curiosity and problem-solving mindset.\n    \n    \n        » List Machine Learning Systems\n    \n\n\n\n\nData science combines mathematics, computer science, and business acumen to extract valuable insights from raw data, helping organizations make informed decisions and achieve growth. Data science merges math, computer science, and business expertise to uncover valuable insights from data, empowering organizations to make informed decisions and drive growth.\nThe initial years are about gaining experience, refining skills, understanding data intricacies, and learning how to leverage various data science tools. As you move further in your career, you’ll be confronted with more complex challenges, requiring not just technical proficiency but also strong business acumen and excellent communication skills.\n\n\n\n                                                \n\n\nYou must be prepared to constantly update your knowledge, learn new techniques, and adapt to new technologies. This persistent learning attitude is what separates a good data scientist from a great one.\n\nThe Problem-Solving Framework\nProblem-solving involves a systematic approach to understanding and resolving issues. To begin, it is crucial to clearly define the problem and gather relevant information to understand its key components comprehensively. Analyzing the root causes helps identify underlying factors, patterns, connections, and potential obstacles contributing to the problem. Once a detailed analysis is conducted, it’s time to generate alternative solutions, encouraging creativity and considering different perspectives.\nEvaluating the options involves assessing their advantages, disadvantages, feasibility, and potential risks and benefits. Based on this evaluation, a suitable solution can be selected, considering the potential impact on stakeholders. With a decision in place, an action plan can be developed, outlining clear goals, milestones, and responsibilities.\nImplementing the preferred solution requires implementing the action plan, monitoring progress, making necessary adjustments, and overcoming challenges. Once the solution is implemented, it is essential to evaluate the results by assessing the outcomes and comparing them to the desired goals to evaluate effectiveness.\nLearning and iterating are critical components of the problem-solving process, as they allow for reflection, identification of lessons learned, and areas for improvement.\n\n\n\n\nflowchart TD\n    A[Identify and understand the problem] --&gt; B[Analyze the root causes]\n    B --&gt;|Generate alternative solutions| C[Evaluate the options]\n    C --&gt; D[Make a decision]\n    D --&gt; F[Develop an action plan]\n    F --&gt; G[Implement the solution]\n    G --&gt; I[Learn and iterate]\n    I --&gt; C\n    B ----&gt;| No Extract| E[New Model]\n\n\n\n\n\n\n\n\n\n\nFeedback\nEmbracing a growth mindset and being receptive to feedback are valuable qualities. Criticism, whether constructive or not, can be a powerful tool for learning and personal development. In the dynamic field of data science, there is always something new to discover and explore. The journey of learning and growing is ongoing, as the field continues to evolve.\nPlease share your feedback with us.\n\n\n\n\n\nSuggestion for you to learn today. See the list of machine learning systems.\n\n\nYOU CAN START TO LEARN WITH RANK RELEVANT ADS"
  },
  {
    "objectID": "start-here.html",
    "href": "start-here.html",
    "title": "The quickest route to acquiring knowledge is through practice.",
    "section": "",
    "text": "We strongly believe that the best way to acquire knowledge is through practical experience. That’s why we prioritize experiential learning and recognize the importance of diverse perspectives and identities in education. Our approach to learning is collaborative, interactive, and rooted in shared cultural practices. We value personal autonomy, creativity, and self-fulfillment. It’s worth noting that we do not use rewards or punishments to influence learning.\nLearning data science is a continuous journey, and embracing the learning process is essential. Feel free to experiment, make mistakes, and ask questions. With time and practice, you’ll become more comfortable with Data Science and be able to tackle increasingly complex tasks. We suggest using Python for web development, applications, or data science; however, it is not the only option in the market.\nflowchart TD\n    A[Data Science] --&gt; B{Tool}\n    B --&gt;|Model| C[Result]\n    C --&gt; D[Conclusion]\n    D --&gt; B\n    B ----&gt;|No| E[End]\nHere are some steps you can take to learn data science:"
  },
  {
    "objectID": "start-here.html#numpy",
    "href": "start-here.html#numpy",
    "title": "The quickest route to acquiring knowledge is through practice.",
    "section": "NumPy",
    "text": "NumPy\nNumPy is a powerful Python library for numerical computing. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays efficiently. NumPy is widely used in scientific computing, data analysis, and machine learning.\n\n\nCode\n'''\nIn this code snippet, we are importing the NumPy library and giving it an alias np. NumPy is a library for numerical computing in Python that provides support for arrays and matrices.\n\nNext, we are creating a NumPy array a using the arange() function, which creates an array of integers from 0 to 14. We then use the reshape() function to reshape the array into a 3x5 matrix.\n'''\nimport numpy as np\na = np.arange(15).reshape(3, 5)\na\n\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])"
  },
  {
    "objectID": "start-here.html#matplotlib",
    "href": "start-here.html#matplotlib",
    "title": "The quickest route to acquiring knowledge is through practice.",
    "section": "Matplotlib",
    "text": "Matplotlib\nMatplotlib is a popular Python library used for creating visualizations and plots. It provides a wide range of functionality for generating various types of charts, graphs, and plots. Here’s a brief introduction to get you started with Matplotlib.\n\n\nCode\n'''\nIn this code snippet, we are importing the pyplot module from the matplotlib library and giving it an alias plt. matplotlib is a plotting library for Python that provides a wide range of tools for creating visualizations.\n\nNext, we are creating a new figure using the figure() function from pyplot. We then create three NumPy arrays x, y, and yerr using the arange() and linspace() functions. These arrays are used to generate a sine wave with some error bars.\n\nWe then set the face color of the figure to #c9c9c9 using the figure() function from pyplot.\n\nNext, we use the errorbar() function from pyplot to plot the sine wave with error bars. We create four different plots with different combinations of upper and lower limits on the error bars. We also add labels to each plot using the label parameter.\n\nFinally, we use the legend() function from pyplot to add a legend to the plot and the show() function to display the plot.\n\nThis code demonstrates how to use matplotlib to create a plot with error bars and a legend. matplotlib provides a wide range of tools for creating visualizations, making it a popular choice for data analysis and scientific computing.\n'''\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nx = np.arange(10)\ny = 2.5 * np.sin(x / 20 * np.pi)\nyerr = np.linspace(0.05, 0.2, 10)\nplt.figure(facecolor='#c9c9c9')\n\nplt.errorbar(x, y + 3, yerr=yerr, label='both limits (default)')\nplt.errorbar(x, y + 2, yerr=yerr, uplims=True, label='uplims=True')\nplt.errorbar(x, y + 1, yerr=yerr, uplims=True, lolims=True,\n             label='uplims=True, lolims=True')\n\nupperlimits = [True, False] * 5\nlowerlimits = [False, True] * 5\nplt.errorbar(x, y, yerr=yerr, uplims=upperlimits, lolims=lowerlimits,\n             label='subsets of uplims and lolims')\n\nplt.legend(loc='lower right')\nplt.show(fig)\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "start-here.html#plotly",
    "href": "start-here.html#plotly",
    "title": "The quickest route to acquiring knowledge is through practice.",
    "section": "Plotly",
    "text": "Plotly\nPlotly is a powerful data visualization library that allows you to create interactive and dynamic visualizations in Python. It supports a wide range of chart types, including line plots, scatter plots, bar charts, histograms, and more. In addition to Python, Plotly also has APIs for R, MATLAB, JavaScript, and other programming languages.\n\n\nCode\n'''\nIn this code snippet, we are importing the plotly.express module and giving it an alias px. plotly is a Python library for creating interactive visualizations, and plotly.express is a high-level interface for creating many types of plots.\n\nNext, we are importing the plotly.io module and giving it an alias pio. This module provides tools for exporting plots to various file formats.\n\nWe then load the gapminder dataset from plotly.express using the data() function and store it in a variable gapminder. This dataset contains information about life expectancy, GDP per capita, and population for various countries over time.\n\nWe then filter the dataset to only include data from the year 2007 using the query() function and store the result in a variable gapminder2007.\n\nNext, we use the scatter() function from plotly.express to create a scatter plot of GDP per capita vs. life expectancy, with markers colored by continent and sized by population. We also set the maximum marker size to 60 and specify the country name as the hover text.\n\nFinally, we use the update_layout() function to set the background color of the plot to #c9c9c9 and the show() function to display the plot.\n\nThis code demonstrates how to use plotly and plotly.express to create an interactive scatter plot with colored markers and hover text. plotly provides a wide range of tools for creating interactive visualizations, making it a popular choice for data analysis and scientific computing.\n'''\nimport plotly.express as px\nimport plotly.io as pio\ngapminder = px.data.gapminder()\ngapminder2007 = gapminder.query(\"year == 2007\")\nfig = px.scatter(gapminder2007, \n                 x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", \n                 size=\"pop\", size_max=60,\n                 hover_name=\"country\")\nfig.update_layout(paper_bgcolor='#c9c9c9', plot_bgcolor='#c9c9c9')\nfig.show()"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Articles",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nCategories\n\n\nDate\n\n\n\n\n\n\nData-Driven and Intuition-Based Approaches in Decision-Making\n\n\nDecisions,Critical-thinking\n\n\nJun 2023\n\n\n\n\nEuler’s Identity\n\n\nMaths,LaTeX\n\n\nJun 2023\n\n\n\n\nSimple Linear Regression\n\n\nlinear-regression\n\n\nMar 2023\n\n\n\n\nMultiple Linear Regression\n\n\nmultiple-regression\n\n\nFeb 2023\n\n\n\n\nRead Multiple CSVs Files\n\n\npython,pandas\n\n\nJan 2023\n\n\n\n\nTwo Sample Z-Test\n\n\nstatistics,python\n\n\nNov 2022\n\n\n\n\n\n\nNo matching items"
  }
]